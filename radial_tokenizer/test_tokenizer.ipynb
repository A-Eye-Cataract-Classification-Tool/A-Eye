{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c18113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== RADIAL TOKENIZER TEST ======\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from radial_tokenizer import RadialTokenizer  # Import from same folder\n",
    "\n",
    "# ==== CONFIG ====\n",
    "IMG_PATH = \"C:/Users/denni/Downloads/test.png\"\n",
    "IMG_NAME = \"sample1\"\n",
    "OUTPUT_DIR = \"../output\"\n",
    "TOK192_DIR = os.path.join(OUTPUT_DIR, \"tokens_192D\")\n",
    "WEIGHTS_DIR = os.path.join(OUTPUT_DIR, \"projection_weights\")\n",
    "RING_IMG_PATH = os.path.join(OUTPUT_DIR, f\"{IMG_NAME}_rings.png\")\n",
    "\n",
    "os.makedirs(TOK192_DIR, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "# ==== LOAD IMAGE ====\n",
    "image = cv2.imread(IMG_PATH)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"Image not found at {IMG_PATH}\")\n",
    "\n",
    "image = cv2.resize(image, (128, 128))\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_norm = image_rgb / 255.0\n",
    "img_tensor = torch.from_numpy(image_norm).permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "print(f\"‚úÖ Loaded Image Tensor Shape: {img_tensor.shape}\")\n",
    "\n",
    "# ==== INIT TOKENIZER ====\n",
    "tokenizer = RadialTokenizer()\n",
    "\n",
    "# ==== VISUALIZE RINGS (different colors) ====\n",
    "ring_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 165, 0)]  # Blue, Green, Red, Orange\n",
    "rings = tokenizer.rings\n",
    "center = tokenizer.center\n",
    "image_with_rings = image_rgb.copy()\n",
    "\n",
    "for idx, (r0, r1) in enumerate(rings):\n",
    "    cv2.circle(image_with_rings, center, r1, ring_colors[idx], 1)\n",
    "    if r0 > 0:\n",
    "        cv2.circle(image_with_rings, center, r0, ring_colors[idx], 1)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(image_with_rings)\n",
    "plt.title(\"Radial Tokenizer Rings Overlay (Colored)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# ==== RUN TOKENIZER ====\n",
    "tokens_192d = tokenizer(img_tensor)  # Shape: [1, 4, 192]\n",
    "print(f\"‚úÖ Tokens Shape (192D): {tokens_192d.shape}\")\n",
    "\n",
    "# ==== SAVE OUTPUTS ====\n",
    "torch.save(tokens_192d.cpu(), os.path.join(TOK192_DIR, f\"{IMG_NAME}.pt\"))\n",
    "torch.save(tokenizer.projector.state_dict(), os.path.join(WEIGHTS_DIR, f\"{IMG_NAME}.pt\"))\n",
    "\n",
    "print(f\"üíæ Saved 192D tokens to: {os.path.join(TOK192_DIR, f'{IMG_NAME}.pt')}\")\n",
    "print(f\"üíæ Saved projection weights to: {os.path.join(WEIGHTS_DIR, f'{IMG_NAME}.pt')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== RADIAL POSITIONAL ENCODING TEST ======\n",
    "import torch\n",
    "import os\n",
    "from radial_positional_encoding import RadialPositionEmbedding\n",
    "\n",
    "IMG_NAME = \"sample1\"\n",
    "OUTPUT_DIR = \"../output\"\n",
    "TOK192_DIR = os.path.join(OUTPUT_DIR, \"tokens_192D\")\n",
    "ENCODED_DIR = os.path.join(OUTPUT_DIR, \"encoded_tokens\")\n",
    "\n",
    "os.makedirs(ENCODED_DIR, exist_ok=True)\n",
    "\n",
    "# ==== LOAD PROJECTED TOKENS ====\n",
    "tokens_192d = torch.load(os.path.join(TOK192_DIR, f\"{IMG_NAME}.pt\"))\n",
    "\n",
    "# ==== RUN POSITIONAL ENCODER ====\n",
    "encoder = RadialPositionEmbedding()\n",
    "encoded_tokens = encoder(tokens_192d)\n",
    "torch.save(encoded_tokens.cpu(), os.path.join(ENCODED_DIR, f\"encoded_{IMG_NAME}.pt\"))\n",
    "\n",
    "print(f\"‚úÖ Encoded tokens shape: {encoded_tokens.shape}\")\n",
    "print(f\"üíæ Saved encoded tokens to: {os.path.join(ENCODED_DIR, f'encoded_{IMG_NAME}.pt')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf65637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== VALIDATE OUTPUT SHAPES & CONTENT ======\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "IMG_NAME = \"sample1\"\n",
    "OUTPUT_DIR = \"../output\"\n",
    "TOK192_DIR = os.path.join(OUTPUT_DIR, \"tokens_192D\")\n",
    "ENCODED_DIR = os.path.join(OUTPUT_DIR, \"encoded_tokens\")\n",
    "WEIGHTS_DIR = os.path.join(OUTPUT_DIR, \"projection_weights\")\n",
    "\n",
    "# ==== LOAD FILES ====\n",
    "tokens_192d = torch.load(os.path.join(TOK192_DIR, f\"{IMG_NAME}.pt\"))\n",
    "projection_weights = torch.load(os.path.join(WEIGHTS_DIR, f\"{IMG_NAME}.pt\"))\n",
    "encoded_tokens = torch.load(os.path.join(ENCODED_DIR, f\"encoded_{IMG_NAME}.pt\"))\n",
    "\n",
    "# ==== SHAPE & DTYPE VALIDATION ====\n",
    "assert tokens_192d.shape == (1, 4, 192), f\"‚ùå 192D token shape mismatch: {tokens_192d.shape}\"\n",
    "assert encoded_tokens.shape == (1, 4, 192), f\"‚ùå Encoded token shape mismatch: {encoded_tokens.shape}\"\n",
    "assert tokens_192d.dtype == torch.float32, \"‚ùå 192D tokens dtype is not float32\"\n",
    "assert encoded_tokens.dtype == torch.float32, \"‚ùå Encoded tokens dtype is not float32\"\n",
    "print(\"‚úÖ Shape and dtype checks passed.\")\n",
    "\n",
    "# ==== PRINT FULL CONTENT ====\n",
    "print(\"\\n=== FULL 192D TOKENS (Projected) ===\")\n",
    "df_proj = pd.DataFrame(tokens_192d.squeeze(0).detach().numpy())\n",
    "print(df_proj.to_string(index=True))\n",
    "\n",
    "print(\"\\n=== FULL ENCODED TOKENS ===\")\n",
    "df_enc = pd.DataFrame(encoded_tokens.squeeze(0).detach().numpy())\n",
    "print(df_enc.to_string(index=True))\n",
    "\n",
    "print(\"\\n=== PROJECTION WEIGHTS ===\")\n",
    "for name, weights in projection_weights.items():\n",
    "    print(f\"\\nLayer: {name}\")\n",
    "    print(weights.detach().numpy())\n",
    "\n",
    "# ==== VISUALIZE GRAPH: PROJECTED TOKENS ====\n",
    "tokens_proj_np = tokens_192d.squeeze(0).detach().numpy()\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(4):\n",
    "    plt.plot(tokens_proj_np[i], label=f\"Ring {i+1}\")\n",
    "plt.title(\"192D Projected Tokens Per Ring\")\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==== VISUALIZE GRAPH: ENCODED TOKENS ====\n",
    "tokens_enc_np = encoded_tokens.squeeze(0).detach().numpy()\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(4):\n",
    "    plt.plot(tokens_enc_np[i], label=f\"Ring {i+1}\")\n",
    "plt.title(\"192D Encoded Tokens Per Ring\")\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
